{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Generalization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Links:\n",
    "- [Task1: Multiple choice](#Task1)\n",
    "- [Task2: Questions](#Task2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Task1'></a>\n",
    "## Task1: Multiple choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "#### Question 1.1\n",
    "\n",
    "\n",
    "What does this represent?\n",
    "\n",
    "<img src=\"images/q1.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Options:\n",
    "1. A model\n",
    "2. An example\n",
    "3. <font color='green'>A hypothesis</font>\n",
    "4. In-sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "#### Question 1.2\n",
    "\n",
    "What is an effect of choosing the best (in-smaple) from two hypothesis?\n",
    "\n",
    "<img src=\"images/q2.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Options:\n",
    "1. Out-of-sampe error decrease\n",
    "2. <font color='green'>Lower probability of generalization</font>\n",
    "3. In-sample error increase\n",
    "4. Higher probability of generalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Question 1.3\n",
    "\n",
    "Which statement is true?\n",
    "\n",
    "$$\\quad\\quad \\,\\, \\hat{y} = sign(ax^3+bx+c)$$\n",
    "$$\\hat{y} = sign(ax+c)$$\n",
    "\n",
    "Options:\n",
    "1. <font color='green'>$ax^3 + bx + c$ have a larger hypothesis space</font>\n",
    "2. $ax^3 + bx + c$ have a smaller hypothesis space\n",
    "3. Their hypothesis space is of the same size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.4\n",
    "\n",
    "Which statement is true?\n",
    "\n",
    "$$\\;\\; \\hat{y} = sign(ax^2+c)$$\n",
    "$$\\hat{y} = sign(ax+c)$$\n",
    "\n",
    "Options:\n",
    "1. $ax^2+c$ have a larger hypothesis space\n",
    "2. $ax^2+c$ have a smaller hypothesis space\n",
    "3. <font color='green'>Their hypothesis space is of the same size</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.5\n",
    "\n",
    "What is the VC dimension of a linear classifier in 3D (plane)\n",
    "\n",
    "<img src=\"images/q5.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Options:\n",
    "1. $d_{VC} = 3$ \n",
    "2. <font color='green'>$d_{VC} = 4$</font>\n",
    "3. $d_{VC} = 7$  \n",
    "4. $d_{VC} = 8$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.6\n",
    "\n",
    "What is the VC dimension of a n dimensional linear classifier?\n",
    "\n",
    "Options:\n",
    "1. <font color='green'>$n+1$</font>\n",
    "2. $n^2+1$\n",
    "3. $n^2-(n-1)^2-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.7\n",
    "\n",
    "What is true about the VC dimension of a model?\n",
    "\n",
    "Options:\n",
    "1. A model with high VC dimension is more likely to underfit\n",
    "2. More training examples will give a lower VC dimension\n",
    "3. A higher VC dimension give a better classifier\n",
    "4. <font color='green'>A model with high VC dimension is more likely to overfit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.8\n",
    "\n",
    "Will using the K-Nearest Neighbors classifier with k=1 imply:\n",
    "\n",
    "Options:\n",
    "1. <font color='green'>Most likely to overfit</font>\n",
    "2. Most likely to underfit\n",
    "3. Depends on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.9\n",
    "\n",
    "Given an unknown class distribution, which line is probably the best classification boundary?\n",
    "\n",
    "<img src=\"images/q9.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Options:\n",
    "1. The left line\n",
    "2. The right line\n",
    "3. <font color='green'>They are both equally good </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.10\n",
    "\n",
    "What effect does adding a regularization term has on the hypothesis space?\n",
    "\n",
    "<img src=\"images/q10.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Options:\n",
    "1. No effect\n",
    "2. <font color='green'>Decreasing the hypothesis space</font>\n",
    "3. Increasing the hypothesis space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='Task2'></a>\n",
    "## Task2: Questions\n",
    "\n",
    "Give short answers to the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 2.1\n",
    "\n",
    "Early stopping is often used to prevent (limit) overfitting. Is the out-of-sample error estimate from the validation set a good estimate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "<font color='green'>The labelled data available is often spilt into a training set, a development (validation) set and a test set. We use the development set to find the best model by tuning parameters such as network architecture, learning rate, regularization coefficient, etc. Early stopping is an option for reducing overfitting. At the end we choose the model with the lowest development loss (error) as our model. This model is found by iteratively testing multiple hypotheses, and will be a too optimistic estimate of the true out-of-sample error. A better estimate would be to use the error from the test set. </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 2.2\n",
    "\n",
    "How can we improve the out-of-sample error when we have a small dataset only?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "<font color='green'>We have a couple of options:</font>\n",
    "\n",
    "<font color='green'>\n",
    "-  Increase the size of the dataset by augmenting the data\n",
    "-  Reduce the hypothesis space by including a regularization term in the cost function. \n",
    "-  Make it harder for the network to memorize the input data by using dropout.\n",
    "-  Use parts of a pre-trained network which are trained on a large dataset. The pre-trained network should have many general features and have been trained on a harder task.</font>\n",
    "- \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
