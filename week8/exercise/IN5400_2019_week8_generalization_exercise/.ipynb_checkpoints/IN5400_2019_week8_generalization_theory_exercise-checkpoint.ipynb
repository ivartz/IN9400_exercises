{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Generalization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Links:\n",
    "- [Task1: Multiple choice](#Task1)\n",
    "- [Task2: Questions](#Task2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Task1'></a>\n",
    "## Task1: Multiple choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "#### Question 1.1\n",
    "\n",
    "\n",
    "What does this represent?\n",
    "\n",
    "<img src=\"images/q1.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Options:\n",
    "1. A model\n",
    "2. An example\n",
    "3. __A hypothesis__\n",
    "4. In-sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "#### Question 1.2\n",
    "\n",
    "What is an effect of choosing the best (in-smaple) from two hypothesis?\n",
    "\n",
    "<img src=\"images/q2.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Options:\n",
    "1. Out-of-sampe error decrease\n",
    "2. __Lower probability of generalization__\n",
    "3. In-sample error increase\n",
    "4. Higher probability of generalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Question 1.3\n",
    "\n",
    "Which statement is true?\n",
    "\n",
    "$$\\quad\\quad \\,\\, \\hat{y} = sign(ax^3+bx+c)$$\n",
    "$$\\hat{y} = sign(ax+c)$$\n",
    "\n",
    "Options:\n",
    "1. __$ax^3 + bx + c$ have a larger hypothesis space__\n",
    "2. $ax^3 + bx + c$ have a smaller hypothesis space\n",
    "3. Their hypothesis space is of the same size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.4\n",
    "\n",
    "Which statement is true?\n",
    "\n",
    "$$\\;\\; \\hat{y} = sign(ax^2+c)$$\n",
    "$$\\hat{y} = sign(ax+c)$$\n",
    "\n",
    "Options:\n",
    "1. $ax^2+c$ have a larger hypothesis space\n",
    "2. $ax^2+c$ have a smaller hypothesis space\n",
    "3. __Their hypothesis space is of the same size__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.5\n",
    "\n",
    "What is the VC dimension of a linear classifier in 3D (plane)\n",
    "\n",
    "<img src=\"images/q5.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Options:\n",
    "1. $d_{VC} = 3$ \n",
    "2. $d_{VC} = 4$ __this__\n",
    "3. $d_{VC} = 7$  \n",
    "4. $d_{VC} = 8$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.6\n",
    "\n",
    "What is the VC dimension of a n dimensional linear classifier?\n",
    "\n",
    "Options:\n",
    "1. $n+1$ __this__\n",
    "2. $n^2+1$\n",
    "3. $n^2-(n-1)^2-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.7\n",
    "\n",
    "What is true about the VC dimension of a model?\n",
    "\n",
    "Options:\n",
    "1. A model with high VC dimension is more likely to underfit\n",
    "2. More training examples will give a lower VC dimension \n",
    "3. A higher VC dimension give a better classifier \n",
    "4. A model with high VC dimension is more likely to overfit __true__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.8\n",
    "\n",
    "Will using the K-Nearest Neighbors classifier with k=1 imply:\n",
    "\n",
    "Options:\n",
    "1. Most likely to overfit __true__\n",
    "2. Most likely to underfit\n",
    "3. Depends on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.9\n",
    "\n",
    "Given an unknown class distribution, which line is probably the best classification boundary?\n",
    "\n",
    "<img src=\"images/q9.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Options:\n",
    "1. The left line\n",
    "2. The right line\n",
    "3. __They are both equally good__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 1.10\n",
    "\n",
    "What effect does adding a regularization term has on the hypothesis space?\n",
    "\n",
    "<img src=\"images/q10.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Options:\n",
    "1. No effect\n",
    "2. __Decreasing the hypothesis space__\n",
    "3. Increasing the hypothesis space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='Task2'></a>\n",
    "## Task2: Questions\n",
    "\n",
    "Give short answers to the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 2.1\n",
    "\n",
    "Early stopping is often used to prevent (limit) overfitting. Is the out-of-sample error estimate from the validation set a good estimate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Yes, since the model is trained on in-sample. However, out-of-sample error estimate from the test set would be better, since exploring hypothesis space is not affected by the test set erro (but is affected by validation set error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 2.2\n",
    "\n",
    "How can we improve the out-of-sample error when we have a small dataset only?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "* Augmentation to make more data.\n",
    "* Regularization to prevent overfitting with too complex model (reducing hypothesis space).\n",
    "* Dropout to make it harder for the network to memorize the data.\n",
    "* Transfer learning; using pretrained network, then retraining specific (i. e. last layers on the small dataset)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
