{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>Note: Do NOT run any of these cells/scripts on UIO IFI computers! (Explanation below)  </b></span> \n",
    "\n",
    "In this mandaroty exercise you are implementing an image captioning network. For training and validation data you will need images with corresponding descriptions. The dataset that you will use is the \"Common Object in Context\" (COCO) 2017. You will also need pretrained weights form the VGG16 network.\n",
    "\n",
    "If you are working on a UIO IFI computer data will be avaibale for you on the project disk. The *path* is given to you in the assigment. The dataset is large (~18GB) and every student cannot download it on the UIO IFI computers. It also takes too long time to produce VGG16 features which is needed for the imaging captioning task. However, if you are working on your own computer, you will need to follow the steps in this notebook to be able to complete the exercise. Downloading the dataset, generating the vocabulary and processing VGG16 features will take a long time. It will depend on your internet connection and compute power.\n",
    "\n",
    "This notebook will help you with:\n",
    "- Downloading and unzipping training and validation data from the COCO 2017 dataset\n",
    "- Generating a vocabulary dictionary holding information about the captions and the corresponding tokens.\n",
    "- Downloading and unzipping the VGG16 weights\n",
    "- Produce and store features from the secound fully connected layer in the VGG16 network for all train and validation images.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Links:\n",
    "- [Step1: Download COCO dataset](#Task1)\n",
    "- [Step2: Generate vocabulary](#Task2)\n",
    "- [Step3: Download VGG16 weights and produce VGG16 features](#Task3)\n",
    "\n",
    "\n",
    "Software version:\n",
    "- Python 3.6\n",
    "- Pytorch 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "<a id='Task1'></a>\n",
    "### Step1: Download COCO dataset\n",
    "\n",
    "The data can be found in folder \"data/coco\". Subfolder e.g. \"train2017\" contains the training images as jpg files.\n",
    "\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the \"data/coco\" folder and delete the files which were not downloaded correctly before trying again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils_data_preparation.cocoDataset import maybe_download_and_extract_coco, DataLoaderWrapper\n",
    "from utils_data_preparation.produceVGG16_fc7_features import produceVGG16_fc7_features\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = \"cuda\"    #\"cuda\" or \"cpu\"\n",
    "data_dir = \"data/coco/\"\n",
    "\n",
    "# Download coco dataset\n",
    "maybe_download_and_extract_coco(data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='Task2'></a>\n",
    "### Step2: Generate vocabulary ###\n",
    "\n",
    "\n",
    "The vocabulary will be stored as a pickle file at \"data/coco/vocabulary\"\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the \"data/coco/vocabulary\" folder and delete the file if it was not downloaded correctly before trying again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloaders (train / val)\n",
    "myDataLoader = DataLoaderWrapper(data_dir)\n",
    "\n",
    "# Generate vocabulary\n",
    "myDataLoader.generate_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='Task3'></a>\n",
    "### Step3: Download vgg16 weights and produce VGG16 features###\n",
    "\n",
    "The pretrained weights will be stored in folder \"data/coco/model/VGG16\" as a .pth file\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the folder and delete the file if it was not downloaded correctly before trying again.\n",
    "\n",
    "The VGG16 features can be found in folders \"data/coco/Train2017_vgg16_fc7\" and \"data/coco/Val2017_vgg16_fc7\"\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the \"data/coco\" folder and delete \"train2017_vgg16_fc7\" and \"val2017_vgg16_fc7\" before trying again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce pickle files with fc7 features and captions (words and tokens)\n",
    "produceVGG16_fc7_features(myDataLoader, device)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
